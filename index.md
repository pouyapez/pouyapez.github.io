---
layout: default
---
<div class="menu-container noselect">
   <table class="content-table">
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/face.png" style="width:100%">
        </td>
        <td>
          <p class="text right-align text-large add-top-margin" style="width:100%;">
              I am a fifth-year PhD student in Machine Learning at the University of California Irvine, advised by Prof.                       <a href="http://sameersingh.org">Sameer Singh</a>. My main area of interest are Knowledge Graph Completion, Interpretability, Active Learning and Text Generation. 
          </p>
        </td>
      </tr>
   </table>
</div>

# Research Internships

* * *
<ul>
  <li>Semantic Machines at Microsoft Research, summer 2021.</li>
  <li>Siri Knowledge group at Apple, summer 2020.</li>
  <li>Allen Institute for Artificial Intelligence, summer 2019.</li>
  <li>Fujitsu Laboratories of America, summer 2018. </li>
  <li>Chinese University of Hong Kong, summer 2014.  </li>
</ul>

# Professional Experience
* * *

<ul>
   <li>Co-organised Explainable Graph-Based Machine Learning workshop at AKBC <a href="https://xgml.github.io">2021</a>.</li>
  <li>Co-organised Knowledge Bases and Multiple Modalities workshop at AKBC <a href="https://kb-mm.github.io">2019</a> and <a href="https://kb-mm-2020.github.io">2020</a>.</li>
   <li>2021: Reviewer at NeurIPS, NAACL</li>
  <li>2020: Reviewer at NeurIPS, ICLR, AAAI, EMNLP</li>
  <li>2019: Reviewer at NeurIPS, ICLR, EMNLP</li>
  <li>2018: Reviewer at EMNLP</li>
  <li>Volunteer at NeurIPS 2018 and AKBC 2020.</li>
</ul>


# Conference & Journal Publications
* * *

<div class="menu-container noselect">
   <table class="content-table">
    <col width="500px" />
    <col width="800px" />
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/emp-inf.png" width="1000">
        </td>
        <td>
          <p class="text cright-align text-large add-top-margin" style="width:100%;" align="center">
              <font style="font-size:20px">An Empirical Comparison of Instance Attribution Methods for NLP</font><br>
              <font style="font-size:15px"><b>Pouya Pezeshkpour</b>, Sarthak Jain, Byron Wallace, Sameer Singh<br>
              NAACL 2021</font><br> 
             </p><p align="justify"> <font style="font-size:13px">In this work we evaluate the degree to which different potential instance attribution agree with respect to the importance of training samples.
We find that simple retrieval methods yield training instances that differ from those identified via gradient-based methods (such as the IF), but that nonetheless exhibit desirable characteristics similar to more complex attribution methods. </font><br></p>
                      <p align="center">
             <font style="font-size:15px"><a href="https://arxiv.org/pdf/2104.04128.pdf">PDF</a>&nbsp;&nbsp;&nbsp;  <a href="https://github.com/successar/instance_attributions_NLP">Source Code</a> &nbsp;&nbsp;&nbsp;   <a href="https://www.youtube.com/watch?v=b9AbcEDmFyg&t=17s">Video on Youtube</a></font>
             </p>
        </td>
      </tr>
   </table>
</div>

* * *
<div class="menu-container noselect">
   <table class="content-table">
    <col width="500px" />
    <col width="800px" />
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/parsinlu.png" width="1000">
        </td>
        <td>
          <p class="text cright-align text-large add-top-margin" style="width:100%;" align="center">
              <font style="font-size:20px">PARSINLU: A Suite of Language Understanding Challenges for Persian</font><br>
              <font style="font-size:15px">Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, <b>Pouya Pezeshkpour</b>, et al<br>
              TACL 2021</font><br> 
             </p><p align="justify"> <font style="font-size:13px">We introduce PARSINLU, the first benchmark in Persian language that includes a range of high-level tasks, Reading Comprehension, Textual Entailment, etc. These datasets are collected in a multitude of ways, often involving manual annotations by native speakers. This results in over 14.5k new instances across 6 distinct NLU tasks. Besides, we present the first results on state-of-the-art monolingual and multi- lingual pre-trained language models on this benchmark and compare them with human performance, which provides valuable in- sights into our ability to tackle natural language understanding challenges in Persian. </font><br></p>
                      <p align="center">
             <font style="font-size:15px"><a href="https://arxiv.org/pdf/2012.06154.pdf">PDF</a>&nbsp;&nbsp;&nbsp;  <a href="https://github.com/persiannlp/parsinlu">Source Code</a></font>
             </p>
        </td>
      </tr>
   </table>
</div>

* * * 




<div class="menu-container noselect">
   <table class="content-table">
    <col width="500px" />
    <col width="800px" />
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/crowd.jpg" width="1000">
        </td>
        <td>
          <p class="text cright-align text-large add-top-margin" style="width:100%;" align="center">
              <font style="font-size:20px">Revisiting Evaluation of Knowledge Base Completion Models </font><br>
              <font style="font-size:15px"><b>Pouya Pezeshkpour</b>, Yifan Tian, Sameer Singh<br>
              <font style="color:red;">(nominated for best paper award) </font>AKBC 2020 </font><br> 
             </p><p align="justify"> <font style="font-size:13px">In this paper, we first study the shortcomings of the evaluation metrics in knowldge graph Embeddings.  More specifically, we demonstrate that these metrics 1) are unreliable for estimating calibration, 2) make strong assumptions that    are often violated, and 3) do not sufficiently, and consistently, differentiate embedding methods from simple approaches and from each other. To address these issues, we provide a semi-complete KG using a randomly sampled subgraph from the test and validation data of YAGO3-10, allowing us to compute accurate triple classification accuracy on this data. </font><br></p>
           <p align="center">
             <font style="font-size:15px"><a href="https://pouyapez.github.io/yago3-tc/">Project Page</a>  &nbsp;&nbsp;&nbsp; <a href="https://openreview.net/pdf?id=1uufzxsxfL">PDF</a>&nbsp;&nbsp;&nbsp;  <a href="https://github.com/pouyapez/yago3-tc">Source Code</a>  &nbsp;&nbsp;&nbsp;  <a href="https://www.youtube.com/watch?v=y9BHvpqHo1g&t=9s">Video on Youtube</a></font>
             </p>
        </td>
      </tr>
   </table>
</div>

* * *

<div class="menu-container noselect">
   <table class="content-table">
    <col width="500px" />
    <col width="800px" />
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/criage.png" width="1000">
        </td>
        <td>
          <p class="text right-align text-large add-top-margin" style="width:100%;" align="center">
            <font style="font-size:20px">Investigating Robustness and Interpretability of Link Prediction via Adversarial Modifications </font><br>
            <font style="font-size:15px"><b>Pouya Pezeshkpour</b>, Yifan Tian, Sameer Singh<br>
            NAACL 2019</font><br>
            </p><p align="justify"><font style="font-size:13px">In this paper, we propose adversarial modifications for link prediction models: identifying the fact to add into or remove from the knowledge graph that changes the prediction for a target fact after the model is retrained. We introduce an efficient approach to estimate the effect of such modifications by approximating the change in the embeddings when the knowledge graph changes. We use these techniques to evaluate the robustness of link prediction models (by measuring sensitivity to additional facts), study interpretability through the facts most responsible for predictions (by identifying the most influential neighbors), and detect incorrect facts in the knowledge base.</font><br></p>
           <p align="center">
<font style="font-size:15px"><a href="https://pouyapez.github.io/criage/">Project Page</a>  &nbsp;&nbsp;&nbsp;  <a href="https://arxiv.org/pdf/1905.00563.pdf">PDF</a>  &nbsp;&nbsp;&nbsp;  <a href="https://github.com/pouyapez/criage">Source Code</a>  &nbsp;&nbsp;&nbsp;  <a href="https://www.youtube.com/watch?v=irVqAjt664s">Video on Youtube</a></font>
          </p>
        </td>
      </tr>
   </table>
</div>

* * *
<div class="menu-container noselect">
   <table class="content-table">
    <col width="500px" />
    <col width="800px" />
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/graph.jpg" width="1000">
        </td>
        <td>
          <p class="text right-align text-large add-top-margin" align="center">
            <font style="font-size:20px">Embedding Multimodal Relational Data for Knowledge Base Completion</font><br>
            <font style="font-size:15px"><b>Pouya Pezeshkpour</b>, Liyan Chen, Sameer Singh<br>
            EMNLP 2018</font><br>
            </p><p align="justify"><font style="font-size:13px">In this work, we propose multimodal knowledge base embeddings (MKBE) that use different neural encoders for this variety of observed data, and combine them with existing relational models to learn embeddings of the entities and multimodal data. Further, using these learned embedings and different neural decoders, we introduce a novel multimodal imputation model to generate missing multimodal values, like text and images, from information in the knowledge base.</font><br></p>
           <p align="center">
<font style="font-size:15px"><a href="https://pouyapez.github.io/mkbe/">Project Page</a>  &nbsp;&nbsp;&nbsp;   <a href="https://arxiv.org/pdf/1809.01341.pdf">PDF</a>  &nbsp;&nbsp;&nbsp;   <a href="https://github.com/pouyapez/mkbe">Source Code</a>  &nbsp;&nbsp;&nbsp;   <a href="https://www.youtube.com/watch?v=Bt5CccdXHUM&t=2s">Video on Youtube</a></font>
          </p>
        </td>
      </tr>
   </table>
</div>

* * *
<div class="menu-container noselect">
   <table class="content-table">
    <col width="500px" />
    <col width="800px" />
      <tr>
        <td>
          <img class="left-align image noselect" src="/images/2014.png"  width="1000">
        </td>
        <td>
          <p class="text right-align text-large add-top-margin" align="center">
            <font style="font-size:20px">Optimal tradeoff between source and state distortions over a Gaussian channel using single and hybrid digital analog codes</font><br>
            <font style="font-size:15px"><b>Pouya Pezeshkpour</b>, Hamid Behroozi<br>
            IST'2014</font><br>
            </p><p align="justify"><font style="font-size:13px">In this paper, the problem of transmitting an analog Gaussian source over an additive white Gaussian noise (AWGN) channel in the presence of a Gaussian interference known only at the transmitter is investigated. Our goal is to estimate both the analog source and the channel state at the receiver simultaneously. In this work, we present different transmission schemes based on joint source-channel coding. We study hybrid digital-analog (HDA) joint source-channel coding schemes and analyze the region of (mean-squared error) distortion pairs (in estimating the source and the state) that are simultaneously achievable.</font><br></p>
           <p align="center">
<font style="font-size:15px"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7000779">PDF</a></font>
          </p>
        </td>
      </tr>
   </table>
</div>

# Workshop & Symposia 

* * *

<ul>
<!--    <li>Daniel Khashabi, et al,"<a href="https://arxiv.org/pdf/2012.06154.pdf">PARSINLU:
A Suite of Language Understanding Challenges for Persian</a>". arXiv 2020.</li> -->
   <li><b>Pouya Pezeshkpour</b>, Zhengli Zhao, Sameer Singh,"<a href="https://openreview.net/pdf?id=p3m_WpN0rEX">On the Utility of Active Instance Selection for Few-Shot Learning</a>". The HAMLETS workshop at NeurIPS 2020.</li>
  <li><b>Pouya Pezeshkpour</b>, Zhengli Zhao, Sameer Singh,"<a href="https://github.com/EliSchwartz/VL3-Workshop/blob/master/pdfs/36.pdf">Using Data Importance for Effective Active Learning</a>". The CVPR workshop on Visual Learning with Limited Labels (VL3), 2020.</li>
  <li><b>Pouya Pezeshkpour</b>, Yifan Tian, Sameer Singh, "Integrating Local Structure into Knowledge Graph Embeddings". SoCal NLP Symposium 2019.</li>
  <li><b>Pouya Pezeshkpour</b>, Ramya Malursrinivasan, Ajey Chander, "<a href="https://pouyapez.github.io/Generating%20User-friendly%20Explanations%20for%20Loan%20Denials%20using%20GANs.pdf">Generating User-friendly Explanations for Loan Denials using GANs</a>". NIPS 2018 Workshop on Challenges and Opportunities for AI in Financial Services.</li>
  <li><b>Pouya Pezeshkpour</b>, Carlos Guestrin, Sameer Singh, "<a href="https://arxiv.org/pdf/1805.00184.pdf">Compact Factorization of Matrices Using Generalized Round-Rank</a>". Southern California Machine Learning Symposium 2017.</li>
</ul>

# Patents
* * *

<ul>
  <li><b>Pouya Pezeshkpour</b>, Ramya Malursrinivasan, Ajay Chander, "<a href="https://patents.justia.com/patent/20200125640">USER-FRIENDLY EXPLANATION PRODUCTION USING GENERATIVE ADVERSARIAL NETWORKS</a>". US Patent Number 20200125640, 2020.</li>
 <li><b>Pouya Pezeshkpour</b>, Ramya Malursrinivasan, Ajey Chander, "<a href="https://patents.justia.com/patent/20200125975">EXPLANATIONS GENERATION WITH DIFFERENT COGNITIVE VALUES USING GENERATIVE ADVERSARIAL NETWORKS</a>". US Patent Number 20200125975, 2020.</li>
</ul> 
* * *

<p align="center"><a href="https://medium.com/@pezeshkp">Medium</a>    &nbsp;&nbsp;&nbsp;   <a href="https://medium.com/series/my-writings-4de58ce3f034">My Writings</a>  &nbsp;&nbsp;&nbsp;   <a href="https://www.amazon.com/dp/B08DMK9PNM/ref=sr_1_1?dchild=1&keywords=a+bypass+to+nirvana&qid=1595806371&sr=8-1">My Book</a> </p>

